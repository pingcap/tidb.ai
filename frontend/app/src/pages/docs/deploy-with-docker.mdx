# Deploy with Docker & Docker Compose

This document provides instructions for deploying the entire RAG using Docker Compose.

## Deploy

> **Prerequisites:**
>
> 1. Set up a [TiDB Serverless cluster](https://docs.pingcap.com/tidbcloud/tidb-cloud-quickstart).
> 2. Install [Docker Compose](https://docs.docker.com/compose/install/).

1. Clone the repository:

    ```bash
    git clone https://github.com/pingcap/tidb.ai.git
    cd tidb.ai
    ```

2. Select an embedding model for TiDB.AI.

    We recommend using the OpenAI text-embedding-3-small model for TiDB.AI, but you can also use other supported embedding models.

    - OpenAI
        - text-embedding-3-small: EMBEDDING_DIMS=1536, EMBEDDING_MAX_TOKENS=8191
    - JinaAI
        - jina-clip-v1: EMBEDDING_DIMS=768, EMBEDDING_MAX_TOKENS=8192
        - find more in https://jina.ai/embeddings/
    - Local Embedding Server
        - BAAI/bge-m3: EMBEDDING_DIMS=1024, EMBEDDING_MAX_TOKENS=8192

<Callout>
Note: The Embedding Model will be configured at the beggining of the deployment process.  You can not change the embedding model after the deployment.
</Callout>

2. Copy and edit the `.env` file:

    ```bash
    cp .env.example .env
    vim .env # or use another text editor to edit this file
    ```

    Replace the following placeholders with your own values:
    - `SECRET_KEY`: you can generate a random secret key using `python3 -c "import secrets; print(secrets.token_urlsafe(32))"`
    - `TIDB_HOST`, `TIDB_USER`, `TIDB_PASSWORD` and `TIDB_DATABASE`: get them from your [TiDB Serverless cluster](https://tidbcloud.com/)

      - Note: TiDB Serverless will provide a default database name called `test`, if you want to use another database name, you need to create a new database in the TiDB Serverless console.
    - `EMBEDDING_DIMS` and `EMBEDDING_MAX_TOKENS`: set them according to the embedding model you choose before, it can not be changed after the deployment.

3. Migrate the database schema:

    ```bash
    docker compose run backend /bin/sh -c "alembic upgrade head"
    ```

4. Bootstrap the database with initial data:

    ```bash
    docker compose run backend /bin/sh -c "python bootstrap.py"
    ```

    Running the bootstrap script creates an admin user. You can find the username and password in the output.

5. Start the services:

    ```bash
    docker compose up
    ```

    To use the local embedding model, start with the following command:

    ```bash
    docker compose --profile local-embedding-reranker up
    ```

6. Open your browser and visit `http://localhost:3000` to access the web interface.

That's it! You can now use TiDB.AI locally. You can also go to https://tidb.ai to experience the live demo.


## Configuration

After you deploy the tool, you need to initialize the tool by following the popup wizard. The wizard will guide you through the following steps:

* Set up the default LLM model.
* Set up the default Embedding model.
* Set up `Data Source` to index the data.

![initialization](https://github.com/user-attachments/assets/7f9253da-3d6f-4ccd-838d-feed3f0b6f05 "Initialization")


## Upgrade

This section will help you upgrade tidb.ai to the new version.

Suppose you want to upgrade tidb.ai from 0.1.0 to version 0.2.0

1. Edit your docker-compose.yml file to use the new image version.

    ```yaml
    services:
      backend:
        image: tidbai/backend:0.2.0
      frontend:
        image: tidbai/frontend:0.2.0
      background:
        image: tidbai/backend:0.2.0
    ```

2. Pull the new image:

    ```bash
    docker compose pull
    ```

3. Migrate the database schema:

    ```bash
    docker compose run backend /bin/sh -c "alembic upgrade head"
    ```

4. Recreate the docker containers:

    ```bash
    docker compose up -d --force-recreate
    ```

5. Check the logs to ensure everything is working correctly:

    ```bash
    docker compose logs -f
    ```

6. Done!
