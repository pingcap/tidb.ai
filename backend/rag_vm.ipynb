{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaiyl/miniconda3/envs/tidbai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.core.db import Scoped_Session\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import warnings\n",
    "from sqlalchemy.exc import SAWarning\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SAWarning)\n",
    "\n",
    "session = Scoped_Session()\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-4o', api_key=os.getenv(\"OPENAI_API_KEY\"), max_tokens=4096)\n",
    "dspy.settings.configure(lm=turbo)\n",
    "\n",
    "plan_model = \"gpt-4o\"\n",
    "generate_model = \"gpt-4o-mini\"\n",
    "\n",
    "user_query = \"Does TiDB provide strict serializability or serializability?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag.knowledge_graph.graph_store import TiDBGraphStore\n",
    "from app.rag.knowledge_graph import KnowledgeGraphIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "\n",
    "_embed_model = OpenAIEmbedding(\n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_3_SMALL\n",
    ")\n",
    "\n",
    "graph_store = TiDBGraphStore(\n",
    "    dspy_lm=turbo,\n",
    "    session=session,\n",
    "    embed_model=_embed_model,\n",
    ")\n",
    "graph_index =  KnowledgeGraphIndex = KnowledgeGraphIndex.from_existing(\n",
    "    dspy_lm=turbo,\n",
    "    kg_store=graph_store,\n",
    ")\n",
    "\n",
    "def retrieve_knowledge_graph(query):\n",
    "    return graph_index.retrieve_with_weight(\n",
    "        query,\n",
    "        [],\n",
    "        depth=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag.vector_store.tidb_vector_store import TiDBVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_store = TiDBVectorStore(session=session)\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=_embed_model\n",
    ")\n",
    "\n",
    "def retrieve_knowledge_embedded_chunks(query, top_k=5):\n",
    "    retriver = vector_index.as_retriever(\n",
    "        similarity_top_k=5\n",
    "    )\n",
    "\n",
    "    nodes = retriver.retrieve(query)\n",
    "    return [node.text for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate(prompt):\n",
    "    completion = openai.OpenAI().chat.completions.create(\n",
    "        model=generate_model,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "You are an intelligent assistant designed to analyze user queries by performing the following tasks:\n",
    "\n",
    "1. **Analyze the Question**:\n",
    "    - Break down the main question into a dependency graph that outlines the key components and their relationships.\n",
    "\n",
    "2. **Break Down into Subquestions**:\n",
    "    - Decompose the main question into smaller, specific, and manageable subquestions that are conducive to information retrieval.\n",
    "    - Ensure that each subquestion is concrete and directly related to fetching necessary information.\n",
    "    - Identify dependencies between subquestions where the answer to one subquestion is required to formulate or answer another.\n",
    "\n",
    "3. **Generate an Action Plan**:\n",
    "    - For each subquestion, create a corresponding action step to answer it.\n",
    "    - Specify the appropriate tool to be used, any necessary arguments, and output tags for each step.\n",
    "    - Ensure that dependent steps correctly reference the outputs of their prerequisite steps using `{output_tag}` placeholders.\n",
    "\n",
    "**Available APIs/Tools**:\n",
    "\n",
    "1. **Knowledge Graph Tool**:\n",
    "   - **Function**: `retrieve_knowledge_graph(query)`\n",
    "   - **Description**: Retrieves structured knowledge in the form of a graph, focusing on entities and their relationships.\n",
    "   - **Use Cases**:\n",
    "     - Entity Queries\n",
    "     - Relationship Navigation\n",
    "\n",
    "2. **Knowledge Embedded Chunks Tool**:\n",
    "   - **Function**: `retrieve_knowledge_embedded_chunks(query)`\n",
    "   - **Description**: Retrieves detailed source data based on content similarity, suitable for in-depth or context-heavy queries.\n",
    "   - **Use Cases**:\n",
    "     - Content Queries\n",
    "     - Context Retrieval\n",
    "\n",
    "3. **LLM Generate Tool**:\n",
    "   - **Function**: `llm_generate(prompt)`\n",
    "   - **Description**: Generates text based on the provided prompt and retrieved data using a large language model.\n",
    "   - **Use Cases**:\n",
    "     - Summarizing information based on retrieved data\n",
    "     - Generating answers based on retrieved data\n",
    "     - Formulating comparative analyses \n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- **Subquestions Specificity**:\n",
    "  - Each subquestion should be specific and aimed at retrieving precise information.\n",
    "  - Avoid vague or overly broad subquestions that may hinder effective information retrieval.\n",
    "\n",
    "- **Handling Dependencies**:\n",
    "  - Identify and outline dependencies between subquestions.\n",
    "  - Ensure that subquestions requiring information from previous steps reference them appropriately using `{output_tag}` placeholders in their `arguments`.\n",
    "\n",
    "- **Utilizing Tools Effectively**:\n",
    "  - Select the most appropriate tool for each subquestion based on its nature.\n",
    "  - Ensure that `arguments` for each tool are correctly populated, incorporating any necessary data from dependent steps.\n",
    "\n",
    "- **Output Structure**:\n",
    "  - Use `output_tags` to uniquely identify the output of each step.\n",
    "  - Reference these tags in subsequent steps to maintain the flow of information and dependencies.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "*User Query*: \"Could you summary the performance improvement of TiDB in the newest version.\"\n",
    "\n",
    "*Generated Action Plan*:\n",
    "\n",
    "```python\n",
    "[\n",
    "    Step(\n",
    "        id=1,\n",
    "        subquestion='What is the latest version of TiDB?',\n",
    "        tool_used='retrieve_knowledge_graph',\n",
    "        arguments={'query': 'Latest version of TiDB'},\n",
    "        output_tags='latest_version_graph_data'\n",
    "    ),\n",
    "    Step(\n",
    "        id=2,\n",
    "        subquestion='What are the performance improvements in the newest TiDB version?',\n",
    "        tool_used='llm_generate',\n",
    "        arguments={'prompt': 'what is the version number of the TiDB latest version?'},\n",
    "        output_tags='latest_version'\n",
    "    ),\n",
    "    Step(\n",
    "        id=3,\n",
    "        subquestion='What are the performance improvements in the newest TiDB version?',\n",
    "        tool_used='retrieve_knowledge_embedded_chunks',\n",
    "        arguments={'query': 'TiDB {latest_version} performance improvements'},\n",
    "        output_tags='tidb_newest_performance'\n",
    "    ),\n",
    "    Step(\n",
    "        id=4,\n",
    "        subquestion='Summary the performance improvements of TiDB in the newest version.',\n",
    "        tool_used='llm_generate',\n",
    "        arguments={'prompt': 'Summary the performance improvements of TiDB in the newest version based on {tidb_newest_performance}.'},\n",
    "        output_tags='performance_comparison'\n",
    "    )\n",
    "]\n",
    "```\n",
    "\n",
    "Dependency Graph:\n",
    "\n",
    "```python\n",
    "[\n",
    "    DependencyEdge(from_step=1, to_step=2),\n",
    "    DependencyEdge(from_step=2, to_step=3),\n",
    "    DependencyEdge(from_step=3, to_step=4),\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "class Step(BaseModel):\n",
    "    id: int\n",
    "    subquestion: str\n",
    "    tool_used: Optional[str] = None\n",
    "    arguments: Optional[Dict[str, str]] = None\n",
    "    output_tags: Optional[str] = None\n",
    "\n",
    "class DependencyEdge(BaseModel):\n",
    "    from_step: int\n",
    "    to_step: int\n",
    "\n",
    "class QuestionAnalysis(BaseModel):\n",
    "    steps: List[Step]\n",
    "    dependency_graph: List[DependencyEdge]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_instruction},\n",
    "    {\"role\": \"user\", \"content\": user_query},\n",
    "]\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=messages,\n",
    "    response_format=QuestionAnalysis,\n",
    ")\n",
    "\n",
    "message = completion.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step(id=1, subquestion='What is TiDB?', tool_used='retrieve_knowledge_graph', arguments={'query': 'TiDB'}, output_tags='tidb_overview_graph'),\n",
       " Step(id=2, subquestion='What is TiDB?', tool_used='retrieve_knowledge_embedded_chunks', arguments={'query': 'TiDB'}, output_tags='tidb_overview_chunks'),\n",
       " Step(id=3, subquestion='Summarize the information gathered about TiDB.', tool_used='llm_generate', arguments={'prompt': 'Summarize the key points and definitions about TiDB from {tidb_overview_graph} and {tidb_overview_chunks}.'}, output_tags='tidb_summary')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.parsed.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DependencyEdge(from_step=1, to_step=3),\n",
       " DependencyEdge(from_step=2, to_step=3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.parsed.dependency_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "\n",
    "\n",
    "# Step Execution\n",
    "class PlanExecutor:\n",
    "    def __init__(self):\n",
    "        self.state = {\n",
    "            'variables': {}\n",
    "        }\n",
    "    \n",
    "    def log_error(self, message: str):\n",
    "        print(f\"ERROR: {message}\")\n",
    "    \n",
    "    def log_info(self, message: str):\n",
    "        print(f\"INFO: {message}\")\n",
    "    \n",
    "    def log_warning(self, message: str):\n",
    "        print(f\"WARNING: {message}\")\n",
    "    \n",
    "    def save_milestone(self, milestone: str, output):\n",
    "        print(f\"MILESTONE: {milestone}, output: {output}\")\n",
    "\n",
    "    def log_execution(self, message: str):\n",
    "        print(f\"EXECUION: {message}\")\n",
    "    \n",
    "    def retrieve_knowledge_embedded_chunks(self, query: str, top_k: int = 5) -> str:\n",
    "        retriver = vector_index.as_retriever(\n",
    "            similarity_top_k=5\n",
    "        )\n",
    "\n",
    "        nodes = retriver.retrieve(query)\n",
    "        return [node.text for node in nodes]\n",
    "    \n",
    "    def llm_generate(self, prompt: str) -> str:\n",
    "        return llm_generate(prompt)\n",
    "    \n",
    "    def retrieve_knowledge_graph(self, query: str) -> str:\n",
    "        return graph_index.retrieve_with_weight(\n",
    "            query,\n",
    "            [],\n",
    "            depth=1,\n",
    "        )\n",
    "    \n",
    "    # Step Execution Handler\n",
    "    def execute_step_handler(self, step: Step) -> bool:\n",
    "        step_type = step.tool_used\n",
    "        params = step.arguments or {}\n",
    "    \n",
    "        self.log_execution(f\"execute step {step}\")\n",
    "        if step_type == \"retrieve_knowledge_graph\":\n",
    "            query = params.get('query')\n",
    "            if not query:\n",
    "                self.log_error(\"No query provided for 'retrieve_knowledge_graph' instruction.\")\n",
    "                return False, None\n",
    "            result = self.retrieve_knowledge_graph(query)\n",
    "            self.state['variables'][step.output_tags] = result\n",
    "            self.save_milestone(f\"AfterStep{step.id}_KnowledgeGraphRetrieval\", result)\n",
    "            return True, result\n",
    "    \n",
    "        elif step_type == \"retrieve_knowledge_embedded_chunks\":\n",
    "            query = params.get('query')\n",
    "            top_k = int(params.get('top_k', 5))\n",
    "            if not query:\n",
    "                self.log_error(\"No query provided for 'retrieve_knowledge_embedded_chunks' instruction.\")\n",
    "                return False, None\n",
    "            result = self.retrieve_knowledge_embedded_chunks(query, top_k)\n",
    "            self.state['variables'][step.output_tags] = result\n",
    "            self.save_milestone(f\"AfterStep{step.id}_EmbeddedChunksRetrieval\", result)\n",
    "            return True, result\n",
    "    \n",
    "        elif step_type == \"llm_generate\":\n",
    "            prompt = params.get('prompt')\n",
    "            if not prompt:\n",
    "                self.log_error(\"No prompt provided for 'llm_generate' instruction.\")\n",
    "                return False, None\n",
    "            result = self.llm_generate(prompt)\n",
    "            self.state['variables'][step.output_tags] = result\n",
    "            self.save_milestone(f\"AfterStep{step.id}_LLMGeneration\", result)\n",
    "            return True, result\n",
    "    \n",
    "        else:\n",
    "            self.log_warning(f\"Unknown step type: {step_type}\")\n",
    "            return False, None\n",
    "    \n",
    "    # Plan Execution\n",
    "    def execute_plan(self, plan: QuestionAnalysis) -> bool:\n",
    "        plan = copy.deepcopy(plan)\n",
    "        self.log_info(\"Starting plan execution.\")\n",
    "        # Determine execution order based on dependency graph\n",
    "        # Simple approach: execute steps in the order they appear, assuming dependencies are met\n",
    "        for step in plan.steps:\n",
    "            # Replace placeholders in arguments\n",
    "            if step.arguments:\n",
    "                for key, value in step.arguments.items():\n",
    "                    placeholders = re.findall(r'\\{(.*?)\\}', value)\n",
    "                    for tag in placeholders:\n",
    "                        replacement = self.state['variables'].get(tag)\n",
    "                        if replacement:\n",
    "                            value = value.replace(f'{{{tag}}}', str(replacement))\n",
    "                        else:\n",
    "                            self.log_error(f\"Missing value for placeholder '{tag}' in step {step.id}.\")\n",
    "                            return False, None\n",
    "                    step.arguments[key] = value\n",
    "            \n",
    "            # Execute the step\n",
    "            success, result = self.execute_step_handler(step)\n",
    "            if not success:\n",
    "                self.log_error(f\"Execution failed at step {step.id}.\")\n",
    "                return False, None\n",
    "        \n",
    "        self.state['goal_completed'] = True\n",
    "        self.log_info(\"Plan executed successfully.\")\n",
    "        return True, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting plan execution.\n",
      "EXECUION: execute step id=1 subquestion='What is TiDB?' tool_used='retrieve_knowledge_graph' arguments={'query': 'TiDB'} output_tags='tidb_overview_graph'\n",
      "MILESTONE: AfterStep1_KnowledgeGraphRetrieval, output: ([{'id': 17670, 'name': 'TiDB', 'description': 'A distributed SQL database system designed for high availability and scalability. It provides high availability, scalability, and performance. It is used for storing and querying data in a distributed environment. It is designed to be scalable, reliable, and easy to use. It is designed to handle high-volume, high-concurrency workloads. It is a distributed SQL database that is designed to be highly scalable and available. It can also be used to stream data to other systems like Kafka, Hadoop, and Oracle using TiCDC, a feature that utilizes the Kafka connectors protocol on the Confluent Platform.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 56394, 'name': 'Table', 'description': 'A structured collection of data organized into rows and columns, representing a specific entity or concept. It can be created and used in relational databases. It is a collection of data organized into rows and columns, representing a specific entity or concept in a database.  Data compaction can be initiated for a table by checking the `TOTAL_DELTA_ROWS` column in the `INFORMATION_SCHEMA.TIFLASH_TABLES` table.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 66574, 'name': 'TiDB', 'description': 'TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability. It is designed to be highly scalable, available, and consistent. TiDB optimizes query efficiency by performing aggregation at both the coprocessor and TiDB layers.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 46478, 'name': 'TiDB', 'description': 'TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability. TiDB is a distributed relational database management system (RDBMS) that is designed to be scalable, highly available, and consistent. It is also designed to be scalable, reliable, and easy to use. It provides high availability, scalability, and consistency. TiDB is a distributed SQL database that is designed for high availability, scalability, and performance. It is a popular choice for applications that require a robust and reliable database system. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent. It is a popular choice for applications that require high performance and reliability.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 68116, 'name': 'IndexLookupExecutor', 'description': 'IndexLookupExecutor is a component of the TiDB query engine that is responsible for looking up data in indexes.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 17813, 'name': 'Index', 'description': 'A data structure that allows for efficient retrieval of data from a table based on specific values. It is a data structure that allows for efficient retrieval of data based on specific values. It allows for faster retrieval of data based on specific values in a column. Different keys for the same index name in sharded tables can lead to data inconsistency.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 46105, 'name': 'Index', 'description': 'A data structure that allows for efficient retrieval of data from a database. It is used to speed up searches by creating a sorted list of values for a specific column or set of columns. It also speeds up data retrieval by providing a sorted list of values for a specific column or set of columns in a table.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 132890, 'name': 'Vector Search Limitation', 'description': \"Outline several limitations and restrictions associated with TiDB Vector. Here are the key limitations:\\n\\n1. Availability: TiDB Vector Search is currently only available for TiDB Serverless clusters. It is will be available for TiDB Dedicated or TiDB Self-Hosted deployments[^1].\\n\\n2. Vector Dimensions: Each vector can have a maximum of 16,000 dimensions[^1][^2].\\n\\n3. Data Type: Vector data must be single-precision floating-point numbers (Float32). Double-precision floating numbers are currently not supported for Vector data types, although this feature is planned for a future release[^2].\\n\\n4. Unsupported Values: You cannot store `NaN`, `Infinity`, or `-Infinity` values in the vector data type[^2].\\n\\n5. Index Creation: Vector indexes can only be defined and created when the table is created. You cannot create the vector index on demand using DDL statements after the table is created. Similarly, you cannot drop the vector index using DDL statements[^3]. \\n\\n6. Distance Metrics: Only cosine distance and L2 distance are supported for creating vector search indexes. L1 distance and inner product are not currently supported for vector indexes[^3].\\n\\nIt's important to note that TiDB is continuously working to enhance the Vector Search feature, and some of these limitations may be addressed in future releases.\\n\\nExample SQL:\\n\\n- To create an HNSW vector index, specify the index definition in the comment of a column with a vector data type when creating the table. For simplicity, we will use a 3-dimensional vector.\\n```sql\\nCREATE TABLE vector_table_with_index (id INT PRIMARY KEY, embedding VECTOR(3) COMMENT 'hnsw(distance=cosine)');\\n```\\n\\n- Insert some sample data into the table.\\n```\\nINSERT INTO vector_table_with_index (id, embedding) VALUES (1, '[1.0, 2.0, 3.0]'), (2, '[4.0, 5.0, 6.0]'), (3, '[7.0, 8.0, 9.0]');\\n```\\n\\n- Perform a vector search to find the two closest vectors to '[1.0, 2.0, 3.0]' using cosine distance.\\n```sql\\nSELECT id, embedding, VEC_COSINE_DISTANCE(embedding, '[1.0, 2.0, 3.0]') AS distance FROM vector_table_with_index ORDER BY distance LIMIT 2;\\n```\\n\\n\\n[^1]: [Vector Search Limitations | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-limitations)\\n[^2]: [Vector Search Data Types | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-data-types)\\n[^3]: [Vector Search Index | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-index)\\n[^4]: [Continuous Profiling | PingCAP Docs](https://docs.pingcap.com/tidb/v5.3/continuous-profiling)\", 'meta': None, 'entity_type': <EntityType.synopsis: 'synopsis'>}, {'id': 51035, 'name': 'TiDB', 'description': 'TiDB is a distributed, open-source relational database management system (RDBMS) that is designed to be highly scalable and performant. TiDB is a distributed relational database management system (RDBMS) designed for scalability and high availability. It is designed to be scalable, highly available, and easy to use. It is based on the principles of NewSQL and offers a MySQL-compatible interface. It is designed to handle large datasets and high-volume transactions. TiDB is a distributed relational database management system (RDBMS) that provides high availability, scalability, and performance. It is based on the principles of NewSQL and offers features like ACID compliance, horizontal scalability, and strong consistency.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 29470, 'name': 'Update Data', 'description': 'The process of modifying existing data in a database.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 18534, 'name': 'Data Segmentation', 'description': 'The process of dividing data into smaller, manageable units for efficient storage and processing.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 54697, 'name': 'Node Size', 'description': 'The amount of resources allocated to a database node, typically measured in terms of CPU cores and memory.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 18281, 'name': 'Session', 'description': 'A session represents a connection between a client and a database server, allowing the client to execute queries and interact with the database. It is used in TiDB to establish a connection between a client and the database.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 18539, 'name': 'Data Scheduling', 'description': 'The process of distributing data across different nodes in a distributed database system to ensure optimal performance and availability.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 47211, 'name': 'Test results', 'description': 'Test results are the output of a test that is run on a software application.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 102890, 'name': 'TiDB Server', 'description': 'TiDB Server is a core component of the TiDB distributed database system. It acts as the SQL layer, processing and executing SQL queries, and serves as the interface between the end-users’ applications and the distributed storage layer of TiDB. TiDB Server is designed to be MySQL-compatible, allowing for seamless integration with existing MySQL applications. It efficiently handles OLTP (Online Transactional Processing) workloads, making it suitable for large-scale, high-concurrency environments.', 'meta': None, 'entity_type': <EntityType.synopsis: 'synopsis'>}, {'id': 2543, 'name': 'TiDB', 'description': 'TiDB is a MySQL-compatible database, and it is an open-source distributed relational database management system (RDBMS) developed by PingCAP. TiDB is a distributed relational database management system (RDBMS) developed by PingCAP.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 57074, 'name': 'TiDB', 'description': 'TiDB is an open-source distributed relational database management system (RDBMS) designed for high availability, scalability, and performance. TiDB is an open-source, distributed relational database management system (RDBMS) that is designed for high availability, scalability, and performance. It provides high availability, scalability, and consistency. It is also designed to be scalable, highly available, and easy to use. TiDB is a distributed relational database management system (RDBMS) that is designed for high availability, scalability, and performance. TiDB is a distributed relational database management system (RDBMS) that is designed to be highly scalable, available, and consistent. TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}, {'id': 15677, 'name': 'TiDB', 'description': 'TiDB is a distributed SQL database that uses PD for cluster management. It is designed to be scalable, highly available, and consistent. It offers features like horizontal scalability, high availability, and strong consistency. TiDB is also designed to be highly scalable, available, and consistent. TiDB offers high availability, scalability, and strong consistency. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent.', 'meta': None, 'entity_type': <EntityType.original: 'original'>}], [{'id': 84167, 'source_entity_id': 57074, 'target_entity_id': 56394, 'description': 'TiDB supports the creation and manipulation of tables.', 'rag_description': 'TiDB -> TiDB supports the creation and manipulation of tables. -> Table', 'weight': 0}, {'id': 23784, 'source_entity_id': 17670, 'target_entity_id': 18539, 'description': 'TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default.', 'rag_description': 'TiDB -> TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default. -> Data Scheduling', 'weight': 0}, {'id': 23783, 'source_entity_id': 17670, 'target_entity_id': 18534, 'description': 'TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default.', 'rag_description': 'TiDB -> TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default. -> Data Segmentation', 'weight': 0}, {'id': 84170, 'source_entity_id': 57074, 'target_entity_id': 46105, 'description': 'TiDB supports the creation and use of indexes to optimize query performance.', 'rag_description': 'TiDB -> TiDB supports the creation and use of indexes to optimize query performance. -> Index', 'weight': 0}, {'id': 109997, 'source_entity_id': 66574, 'target_entity_id': 68116, 'description': 'TiDB improves memory control and adds statistics about IndexLookupExecutor memory.', 'rag_description': 'TiDB -> TiDB improves memory control and adds statistics about IndexLookupExecutor memory. -> IndexLookupExecutor', 'weight': 0}, {'id': 65295, 'source_entity_id': 46478, 'target_entity_id': 47211, 'description': 'TiDB improves the stability of test results in statistics.', 'rag_description': 'TiDB -> TiDB improves the stability of test results in statistics. -> Test results', 'weight': 0}, {'id': 77841, 'source_entity_id': 51035, 'target_entity_id': 54697, 'description': 'TiDB supports a node size option of 32 vCPU.', 'rag_description': 'TiDB -> TiDB supports a node size option of 32 vCPU. -> Node Size', 'weight': 0}, {'id': 78579, 'source_entity_id': 51035, 'target_entity_id': 29470, 'description': 'TiDB supports updating data using SQL Statements.', 'rag_description': 'TiDB -> TiDB supports updating data using SQL Statements. -> Update Data', 'weight': 0}, {'id': 44215, 'source_entity_id': 2543, 'target_entity_id': 17813, 'description': 'TiDB uses indexes to improve query performance by allowing for faster data retrieval based on specific values in a column.', 'rag_description': 'TiDB -> TiDB uses indexes to improve query performance by allowing for faster data retrieval based on specific values in a column. -> Index', 'weight': 0}, {'id': 23513, 'source_entity_id': 15677, 'target_entity_id': 18281, 'description': 'TiDB loads the TimeZone variable from TiKV when creating a new session.', 'rag_description': 'TiDB -> TiDB loads the TimeZone variable from TiKV when creating a new session. -> Session', 'weight': 0}], [])\n",
      "EXECUION: execute step id=2 subquestion='What is TiDB?' tool_used='retrieve_knowledge_embedded_chunks' arguments={'query': 'TiDB'} output_tags='tidb_overview_chunks'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langfuse:Langfuse client is disabled since no public_key was provided as a parameter or environment variable 'LANGFUSE_PUBLIC_KEY'. See our docs: https://langfuse.com/docs/sdk/python/low-level-sdk#initialize-client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MILESTONE: AfterStep2_EmbeddedChunksRetrieval, output: ['However, it does not support dedi-\\ncated OLAP or HTAP functionality.\\n8. CONCLUSION\\nWe have presented a production-ready, HTAP database: TiDB.\\nTiDB is built on top of TiKV , a distributed, row-based store, which\\nuses the Raft algorithm. We introduce columnar learners for real-\\ntime analysis, which asynchronously replicate logs from TiKV , and\\ntransform row-format data into column format. Such log replica-\\ntion between TiKV and TiFlash provides real-time data consistency\\nwith little overhead. TiKV and TiFlash can be deployed on sepa-\\nrate physical resources to efﬁciently process both transactional and\\nanalytical queries. They can be optimally chosen by TiDB to be\\naccessed when scanning tables for both transactional and analyti-\\ncal queries. Experimental results show TiDB performs well under\\nan HTAP benchmark, CH-benCHmark. TiDB provides a generic\\nsolution to evolve NewSQL systems into HTAP systems.\\n 3083\\n\\n9. REFERENCES\\n[1] Clickhouse. https://clickhouse .tech .\\n[2] LZ4. https://github .com/lz4/lz4 .\\n[3] MemSQL. https://www .memsql .com.\\n[4] Parquet. https://parquet .apache .org.\\n[5] RocksDB. https://rocksdb .org.\\n[6] Sysbench.\\nhttps://github .com/akopytov/sysbench .\\n[7] TiDB. https://github .com/pingcap/tidb .\\n[8] J. Arulraj, A. Pavlo, and P. Menon. Bridging the Archipelago\\nbetween Row-Stores and Column-Stores for Hybrid\\nWorkloads. In SIGMOD , pages 583–598. ACM, 2016.\\n[9] R. Barber, C. Garcia-Arellano, R. Grosman, R. M ¨uller, et al.\\nEvolving Databases for New-Gen Big Data Applications. In\\nCIDR . www.cidrdb.org, 2017.\\n[10] R. Barber, M. Huras, G. M. Lohman, C. Mohan, et al.\\nWildﬁre: Concurrent Blazing Data Ingest and Analytics. In\\nSIGMOD , pages 2077–2080. ACM, 2016.\\n[11] R. Cattell. Scalable SQL and NoSQL data stores. SIGMOD\\nRec., 39(4):12–27, 2010.\\n[12] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A.\\nWallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber.\\nBigtable: A Distributed Storage System for Structured Data.\\nInOSDI , pages 205–218. USENIX Association, 2006.\\n[13] R. L. Cole, F. Funke, L. Giakoumakis, W. Guy, et al. The\\nmixed workload CH-benCHmark. In DBTest 2011 , page 8.\\nACM, 2011.\\n[14] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, et al. Spanner:\\nGoogle’s Globally Distributed Database. ACM Trans.\\nComput. Syst. , 31(3):8:1–8:22, 2013.\\n[15] Z. Fang, B. Zheng, and C. Weng. Interleaved\\nMulti-Vectorizing. PVLDB , 13(3):226–238, 2019.\\n[16] A. Floratou, U. F. Minhas, and F. ¨Ozcan. SQL-on-Hadoop:\\nFull Circle Back to Shared-Nothing Database Architectures.\\nPVLDB , 7(12):1295–1306, 2014.\\n[17] G. Graefe. V olcano - An Extensible and Parallel Query\\nEvaluation System. IEEE Trans. Knowl. Data Eng. ,\\n6(1):120–135, 1994.\\n[18] A. Kemper and T. Neumann. HyPer: A hybrid OLTP&OLAP\\nmain memory database system based on virtual memory\\nsnapshots. In ICDE , pages 195–206. IEEE Computer\\nSociety, 2011.\\n[19] T. Lahiri, S. Chavan, M. Colgan, D. Das, A. Ganesh, et al.', '---\\ntitle: TiDB Introduction\\nsummary: Learn about the key features and usage scenarios of TiDB.\\n---\\n\\n# TiDB Introduction\\n\\n<!-- Localization note for TiDB:\\n\\n- English: use distributed SQL, and start to emphasize HTAP\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\n- Japanese: use NewSQL because it is well-recognized\\n\\n-->\\n\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\n\\nThe following video introduces key features of TiDB.\\n\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>', '---\\ntitle: TiDB Introduction\\nsummary: Learn about the key features and usage scenarios of TiDB.\\n---\\n\\n# TiDB Introduction\\n\\n<!-- Localization note for TiDB:\\n\\n- English: use distributed SQL, and start to emphasize HTAP\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\n- Japanese: use NewSQL because it is well-recognized\\n\\n-->\\n\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\n\\nThe following video introduces key features of TiDB.\\n\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>', '---\\ntitle: TiDB Introduction\\nsummary: Learn about the key features and usage scenarios of TiDB.\\n---\\n\\n# TiDB Introduction\\n\\n<!-- Localization note for TiDB:\\n\\n- English: use distributed SQL, and start to emphasize HTAP\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\n- Japanese: use NewSQL because it is well-recognized\\n\\n-->\\n\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\n\\nThe following video introduces key features of TiDB.\\n\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>', 'TiDB: A Raft-based HTAP Database\\nDongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang∗, Xiaoyu Ma, Fei Xu, Li Shen, Liu Tang,\\nYuxing Zhou, Menglong Huang, Wan Wei, Cong Liu, Jian Zhang, Jianjun Li, Xuelian Wu,\\nLingyu Song, Ruoxi Sun, Shuaipeng Yu, Lei Zhao, Nicholas Cameron, Liquan Pei, Xin Tang\\nPingCAP\\n{huang, liuqi, cuiqiu, fangzhuhe, maxiaoyu, xufei, shenli, tl, z, menglong,\\nweiwan, liucong, zhangjian, jay, wuxuelian, songlingyu, sunruoxi, yusp,\\nzhaolei, nick, liquanpei, tangxin }@pingcap.com\\nABSTRACT\\nHybrid Transactional and Analytical Processing (HTAP) databases\\nrequire processing transactional and analytical queries in isolation\\nto remove the interference between them. To achieve this, it is nec-\\nessary to maintain different replicas of data speciﬁed for the two\\ntypes of queries. However, it is challenging to provide a consistent\\nview for distributed replicas within a storage system, where ana-\\nlytical requests can efﬁciently read consistent and fresh data from\\ntransactional workloads at scale and with high availability.\\nTo meet this challenge, we propose extending replicated state\\nmachine-based consensus algorithms to provide consistent replicas\\nfor HTAP workloads. Based on this novel idea, we present a Raft-\\nbased HTAP database: TiDB. In the database, we design a multi-\\nRaft storage system which consists of a row store and a column\\nstore. The row store is built based on the Raft algorithm. It is scal-\\nable to materialize updates from transactional requests with high\\navailability. In particular, it asynchronously replicates Raft logs to\\nlearners which transform row format to column format for tuples,\\nforming a real-time updatable column store. This column store al-\\nlows analytical queries to efﬁciently read fresh and consistent data\\nwith strong isolation from transactions on the row store. Based on\\nthis storage system, we build an SQL engine to process large-scale\\ndistributed transactions and expensive analytical queries. The SQL\\nengine optimally accesses row-format and column-format replicas\\nof data. We also include a powerful analysis engine, TiSpark, to\\nhelp TiDB connect to the Hadoop ecosystem. Comprehensive ex-\\nperiments show that TiDB achieves isolated high performance un-\\nder CH-benCHmark, a benchmark focusing on HTAP workloads.\\nPVLDB Reference Format:\\nDongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang, Xiaoyu Ma, Fei Xu, Li\\nShen, Liu Tang, Yuxing Zhou, Menglong Huang, Wan Wei, Cong Liu, Jian\\nZhang, Jianjun Li, Xuelian Wu, Lingyu Song, Ruoxi Sun, Shuaipeng Yu,\\nLei Zhao, Nicholas Cameron, Liquan Pei, Xin Tang. TiDB: A Raft-based\\nHTAP Database. PVLDB , 13(12): 3072-3084, 2020.\\nDOI: https://doi.org/10.14778/3415478.3415535\\n1. INTRODUCTION\\nRelational database management systems (RDBMS) are popu-\\nlar with their relational model, strong transactional guarantees, and\\n∗Zhuhe Fang is the corresponding author.\\nThis work is licensed under the Creative Commons Attribution-\\nNonCommercial-NoDerivatives 4.0 International License. To view a copy\\nof this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For\\nany use beyond those covered by this license, obtain permission by emailing\\ninfo@vldb.org. Copyright is held by the owner/author(s). Publication rights\\nlicensed to the VLDB Endowment.\\nProceedings of the VLDB Endowment, V ol. 13, No. 12\\nISSN 2150-8097.\\nDOI: https://doi.org/10.14778/3415478.3415535SQL interface. They are widely adopted in traditional applica-\\ntions, like business systems. However, old RDBMSs do not pro-\\nvide scalability and high availability. Therefore, at the beginning\\nof the 2000s [11], internet applications preferred NoSQL systems\\nlike Google Bigtable [12] and DynamoDB [36].']\n",
      "EXECUION: execute step id=3 subquestion='Summarize the information gathered about TiDB.' tool_used='llm_generate' arguments={'prompt': 'Summarize the key points and definitions about TiDB from ([{\\'id\\': 17670, \\'name\\': \\'TiDB\\', \\'description\\': \\'A distributed SQL database system designed for high availability and scalability. It provides high availability, scalability, and performance. It is used for storing and querying data in a distributed environment. It is designed to be scalable, reliable, and easy to use. It is designed to handle high-volume, high-concurrency workloads. It is a distributed SQL database that is designed to be highly scalable and available. It can also be used to stream data to other systems like Kafka, Hadoop, and Oracle using TiCDC, a feature that utilizes the Kafka connectors protocol on the Confluent Platform.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 56394, \\'name\\': \\'Table\\', \\'description\\': \\'A structured collection of data organized into rows and columns, representing a specific entity or concept. It can be created and used in relational databases. It is a collection of data organized into rows and columns, representing a specific entity or concept in a database.  Data compaction can be initiated for a table by checking the `TOTAL_DELTA_ROWS` column in the `INFORMATION_SCHEMA.TIFLASH_TABLES` table.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 66574, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability. It is designed to be highly scalable, available, and consistent. TiDB optimizes query efficiency by performing aggregation at both the coprocessor and TiDB layers.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 46478, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability. TiDB is a distributed relational database management system (RDBMS) that is designed to be scalable, highly available, and consistent. It is also designed to be scalable, reliable, and easy to use. It provides high availability, scalability, and consistency. TiDB is a distributed SQL database that is designed for high availability, scalability, and performance. It is a popular choice for applications that require a robust and reliable database system. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent. It is a popular choice for applications that require high performance and reliability.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 68116, \\'name\\': \\'IndexLookupExecutor\\', \\'description\\': \\'IndexLookupExecutor is a component of the TiDB query engine that is responsible for looking up data in indexes.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 17813, \\'name\\': \\'Index\\', \\'description\\': \\'A data structure that allows for efficient retrieval of data from a table based on specific values. It is a data structure that allows for efficient retrieval of data based on specific values. It allows for faster retrieval of data based on specific values in a column. Different keys for the same index name in sharded tables can lead to data inconsistency.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 46105, \\'name\\': \\'Index\\', \\'description\\': \\'A data structure that allows for efficient retrieval of data from a database. It is used to speed up searches by creating a sorted list of values for a specific column or set of columns. It also speeds up data retrieval by providing a sorted list of values for a specific column or set of columns in a table.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 132890, \\'name\\': \\'Vector Search Limitation\\', \\'description\\': \"Outline several limitations and restrictions associated with TiDB Vector. Here are the key limitations:\\\\n\\\\n1. Availability: TiDB Vector Search is currently only available for TiDB Serverless clusters. It is will be available for TiDB Dedicated or TiDB Self-Hosted deployments[^1].\\\\n\\\\n2. Vector Dimensions: Each vector can have a maximum of 16,000 dimensions[^1][^2].\\\\n\\\\n3. Data Type: Vector data must be single-precision floating-point numbers (Float32). Double-precision floating numbers are currently not supported for Vector data types, although this feature is planned for a future release[^2].\\\\n\\\\n4. Unsupported Values: You cannot store `NaN`, `Infinity`, or `-Infinity` values in the vector data type[^2].\\\\n\\\\n5. Index Creation: Vector indexes can only be defined and created when the table is created. You cannot create the vector index on demand using DDL statements after the table is created. Similarly, you cannot drop the vector index using DDL statements[^3]. \\\\n\\\\n6. Distance Metrics: Only cosine distance and L2 distance are supported for creating vector search indexes. L1 distance and inner product are not currently supported for vector indexes[^3].\\\\n\\\\nIt\\'s important to note that TiDB is continuously working to enhance the Vector Search feature, and some of these limitations may be addressed in future releases.\\\\n\\\\nExample SQL:\\\\n\\\\n- To create an HNSW vector index, specify the index definition in the comment of a column with a vector data type when creating the table. For simplicity, we will use a 3-dimensional vector.\\\\n```sql\\\\nCREATE TABLE vector_table_with_index (id INT PRIMARY KEY, embedding VECTOR(3) COMMENT \\'hnsw(distance=cosine)\\');\\\\n```\\\\n\\\\n- Insert some sample data into the table.\\\\n```\\\\nINSERT INTO vector_table_with_index (id, embedding) VALUES (1, \\'[1.0, 2.0, 3.0]\\'), (2, \\'[4.0, 5.0, 6.0]\\'), (3, \\'[7.0, 8.0, 9.0]\\');\\\\n```\\\\n\\\\n- Perform a vector search to find the two closest vectors to \\'[1.0, 2.0, 3.0]\\' using cosine distance.\\\\n```sql\\\\nSELECT id, embedding, VEC_COSINE_DISTANCE(embedding, \\'[1.0, 2.0, 3.0]\\') AS distance FROM vector_table_with_index ORDER BY distance LIMIT 2;\\\\n```\\\\n\\\\n\\\\n[^1]: [Vector Search Limitations | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-limitations)\\\\n[^2]: [Vector Search Data Types | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-data-types)\\\\n[^3]: [Vector Search Index | PingCAP Docs](https://docs.pingcap.com/tidbcloud/vector-search-index)\\\\n[^4]: [Continuous Profiling | PingCAP Docs](https://docs.pingcap.com/tidb/v5.3/continuous-profiling)\", \\'meta\\': None, \\'entity_type\\': <EntityType.synopsis: \\'synopsis\\'>}, {\\'id\\': 51035, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is a distributed, open-source relational database management system (RDBMS) that is designed to be highly scalable and performant. TiDB is a distributed relational database management system (RDBMS) designed for scalability and high availability. It is designed to be scalable, highly available, and easy to use. It is based on the principles of NewSQL and offers a MySQL-compatible interface. It is designed to handle large datasets and high-volume transactions. TiDB is a distributed relational database management system (RDBMS) that provides high availability, scalability, and performance. It is based on the principles of NewSQL and offers features like ACID compliance, horizontal scalability, and strong consistency.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 29470, \\'name\\': \\'Update Data\\', \\'description\\': \\'The process of modifying existing data in a database.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 18534, \\'name\\': \\'Data Segmentation\\', \\'description\\': \\'The process of dividing data into smaller, manageable units for efficient storage and processing.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 54697, \\'name\\': \\'Node Size\\', \\'description\\': \\'The amount of resources allocated to a database node, typically measured in terms of CPU cores and memory.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 18281, \\'name\\': \\'Session\\', \\'description\\': \\'A session represents a connection between a client and a database server, allowing the client to execute queries and interact with the database. It is used in TiDB to establish a connection between a client and the database.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 18539, \\'name\\': \\'Data Scheduling\\', \\'description\\': \\'The process of distributing data across different nodes in a distributed database system to ensure optimal performance and availability.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 47211, \\'name\\': \\'Test results\\', \\'description\\': \\'Test results are the output of a test that is run on a software application.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 102890, \\'name\\': \\'TiDB Server\\', \\'description\\': \\'TiDB Server is a core component of the TiDB distributed database system. It acts as the SQL layer, processing and executing SQL queries, and serves as the interface between the end-users’ applications and the distributed storage layer of TiDB. TiDB Server is designed to be MySQL-compatible, allowing for seamless integration with existing MySQL applications. It efficiently handles OLTP (Online Transactional Processing) workloads, making it suitable for large-scale, high-concurrency environments.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.synopsis: \\'synopsis\\'>}, {\\'id\\': 2543, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is a MySQL-compatible database, and it is an open-source distributed relational database management system (RDBMS) developed by PingCAP. TiDB is a distributed relational database management system (RDBMS) developed by PingCAP.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 57074, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is an open-source distributed relational database management system (RDBMS) designed for high availability, scalability, and performance. TiDB is an open-source, distributed relational database management system (RDBMS) that is designed for high availability, scalability, and performance. It provides high availability, scalability, and consistency. It is also designed to be scalable, highly available, and easy to use. TiDB is a distributed relational database management system (RDBMS) that is designed for high availability, scalability, and performance. TiDB is a distributed relational database management system (RDBMS) that is designed to be highly scalable, available, and consistent. TiDB is an open-source distributed relational database management system (RDBMS) designed for scalability and high availability.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}, {\\'id\\': 15677, \\'name\\': \\'TiDB\\', \\'description\\': \\'TiDB is a distributed SQL database that uses PD for cluster management. It is designed to be scalable, highly available, and consistent. It offers features like horizontal scalability, high availability, and strong consistency. TiDB is also designed to be highly scalable, available, and consistent. TiDB offers high availability, scalability, and strong consistency. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent. TiDB is a distributed SQL database that is designed to be scalable, highly available, and consistent.\\', \\'meta\\': None, \\'entity_type\\': <EntityType.original: \\'original\\'>}], [{\\'id\\': 84167, \\'source_entity_id\\': 57074, \\'target_entity_id\\': 56394, \\'description\\': \\'TiDB supports the creation and manipulation of tables.\\', \\'rag_description\\': \\'TiDB -> TiDB supports the creation and manipulation of tables. -> Table\\', \\'weight\\': 0}, {\\'id\\': 23784, \\'source_entity_id\\': 17670, \\'target_entity_id\\': 18539, \\'description\\': \\'TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default.\\', \\'rag_description\\': \\'TiDB -> TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default. -> Data Scheduling\\', \\'weight\\': 0}, {\\'id\\': 23783, \\'source_entity_id\\': 17670, \\'target_entity_id\\': 18534, \\'description\\': \\'TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default.\\', \\'rag_description\\': \\'TiDB -> TiDB splits data into Regions, each representing a range of data with a size limit of 96M by default. -> Data Segmentation\\', \\'weight\\': 0}, {\\'id\\': 84170, \\'source_entity_id\\': 57074, \\'target_entity_id\\': 46105, \\'description\\': \\'TiDB supports the creation and use of indexes to optimize query performance.\\', \\'rag_description\\': \\'TiDB -> TiDB supports the creation and use of indexes to optimize query performance. -> Index\\', \\'weight\\': 0}, {\\'id\\': 109997, \\'source_entity_id\\': 66574, \\'target_entity_id\\': 68116, \\'description\\': \\'TiDB improves memory control and adds statistics about IndexLookupExecutor memory.\\', \\'rag_description\\': \\'TiDB -> TiDB improves memory control and adds statistics about IndexLookupExecutor memory. -> IndexLookupExecutor\\', \\'weight\\': 0}, {\\'id\\': 65295, \\'source_entity_id\\': 46478, \\'target_entity_id\\': 47211, \\'description\\': \\'TiDB improves the stability of test results in statistics.\\', \\'rag_description\\': \\'TiDB -> TiDB improves the stability of test results in statistics. -> Test results\\', \\'weight\\': 0}, {\\'id\\': 77841, \\'source_entity_id\\': 51035, \\'target_entity_id\\': 54697, \\'description\\': \\'TiDB supports a node size option of 32 vCPU.\\', \\'rag_description\\': \\'TiDB -> TiDB supports a node size option of 32 vCPU. -> Node Size\\', \\'weight\\': 0}, {\\'id\\': 78579, \\'source_entity_id\\': 51035, \\'target_entity_id\\': 29470, \\'description\\': \\'TiDB supports updating data using SQL Statements.\\', \\'rag_description\\': \\'TiDB -> TiDB supports updating data using SQL Statements. -> Update Data\\', \\'weight\\': 0}, {\\'id\\': 44215, \\'source_entity_id\\': 2543, \\'target_entity_id\\': 17813, \\'description\\': \\'TiDB uses indexes to improve query performance by allowing for faster data retrieval based on specific values in a column.\\', \\'rag_description\\': \\'TiDB -> TiDB uses indexes to improve query performance by allowing for faster data retrieval based on specific values in a column. -> Index\\', \\'weight\\': 0}, {\\'id\\': 23513, \\'source_entity_id\\': 15677, \\'target_entity_id\\': 18281, \\'description\\': \\'TiDB loads the TimeZone variable from TiKV when creating a new session.\\', \\'rag_description\\': \\'TiDB -> TiDB loads the TimeZone variable from TiKV when creating a new session. -> Session\\', \\'weight\\': 0}], []) and [\\'However, it does not support dedi-\\\\ncated OLAP or HTAP functionality.\\\\n8. CONCLUSION\\\\nWe have presented a production-ready, HTAP database: TiDB.\\\\nTiDB is built on top of TiKV , a distributed, row-based store, which\\\\nuses the Raft algorithm. We introduce columnar learners for real-\\\\ntime analysis, which asynchronously replicate logs from TiKV , and\\\\ntransform row-format data into column format. Such log replica-\\\\ntion between TiKV and TiFlash provides real-time data consistency\\\\nwith little overhead. TiKV and TiFlash can be deployed on sepa-\\\\nrate physical resources to efﬁciently process both transactional and\\\\nanalytical queries. They can be optimally chosen by TiDB to be\\\\naccessed when scanning tables for both transactional and analyti-\\\\ncal queries. Experimental results show TiDB performs well under\\\\nan HTAP benchmark, CH-benCHmark. TiDB provides a generic\\\\nsolution to evolve NewSQL systems into HTAP systems.\\\\n 3083\\\\n\\\\n9. REFERENCES\\\\n[1] Clickhouse. https://clickhouse .tech .\\\\n[2] LZ4. https://github .com/lz4/lz4 .\\\\n[3] MemSQL. https://www .memsql .com.\\\\n[4] Parquet. https://parquet .apache .org.\\\\n[5] RocksDB. https://rocksdb .org.\\\\n[6] Sysbench.\\\\nhttps://github .com/akopytov/sysbench .\\\\n[7] TiDB. https://github .com/pingcap/tidb .\\\\n[8] J. Arulraj, A. Pavlo, and P. Menon. Bridging the Archipelago\\\\nbetween Row-Stores and Column-Stores for Hybrid\\\\nWorkloads. In SIGMOD , pages 583–598. ACM, 2016.\\\\n[9] R. Barber, C. Garcia-Arellano, R. Grosman, R. M ¨uller, et al.\\\\nEvolving Databases for New-Gen Big Data Applications. In\\\\nCIDR . www.cidrdb.org, 2017.\\\\n[10] R. Barber, M. Huras, G. M. Lohman, C. Mohan, et al.\\\\nWildﬁre: Concurrent Blazing Data Ingest and Analytics. In\\\\nSIGMOD , pages 2077–2080. ACM, 2016.\\\\n[11] R. Cattell. Scalable SQL and NoSQL data stores. SIGMOD\\\\nRec., 39(4):12–27, 2010.\\\\n[12] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A.\\\\nWallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber.\\\\nBigtable: A Distributed Storage System for Structured Data.\\\\nInOSDI , pages 205–218. USENIX Association, 2006.\\\\n[13] R. L. Cole, F. Funke, L. Giakoumakis, W. Guy, et al. The\\\\nmixed workload CH-benCHmark. In DBTest 2011 , page 8.\\\\nACM, 2011.\\\\n[14] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, et al. Spanner:\\\\nGoogle’s Globally Distributed Database. ACM Trans.\\\\nComput. Syst. , 31(3):8:1–8:22, 2013.\\\\n[15] Z. Fang, B. Zheng, and C. Weng. Interleaved\\\\nMulti-Vectorizing. PVLDB , 13(3):226–238, 2019.\\\\n[16] A. Floratou, U. F. Minhas, and F. ¨Ozcan. SQL-on-Hadoop:\\\\nFull Circle Back to Shared-Nothing Database Architectures.\\\\nPVLDB , 7(12):1295–1306, 2014.\\\\n[17] G. Graefe. V olcano - An Extensible and Parallel Query\\\\nEvaluation System. IEEE Trans. Knowl. Data Eng. ,\\\\n6(1):120–135, 1994.\\\\n[18] A. Kemper and T. Neumann. HyPer: A hybrid OLTP&OLAP\\\\nmain memory database system based on virtual memory\\\\nsnapshots. In ICDE , pages 195–206. IEEE Computer\\\\nSociety, 2011.\\\\n[19] T. Lahiri, S. Chavan, M. Colgan, D. Das, A. Ganesh, et al.\\', \\'---\\\\ntitle: TiDB Introduction\\\\nsummary: Learn about the key features and usage scenarios of TiDB.\\\\n---\\\\n\\\\n# TiDB Introduction\\\\n\\\\n<!-- Localization note for TiDB:\\\\n\\\\n- English: use distributed SQL, and start to emphasize HTAP\\\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\\\n- Japanese: use NewSQL because it is well-recognized\\\\n\\\\n-->\\\\n\\\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\\\n\\\\nThe following video introduces key features of TiDB.\\\\n\\\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\', \\'---\\\\ntitle: TiDB Introduction\\\\nsummary: Learn about the key features and usage scenarios of TiDB.\\\\n---\\\\n\\\\n# TiDB Introduction\\\\n\\\\n<!-- Localization note for TiDB:\\\\n\\\\n- English: use distributed SQL, and start to emphasize HTAP\\\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\\\n- Japanese: use NewSQL because it is well-recognized\\\\n\\\\n-->\\\\n\\\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\\\n\\\\nThe following video introduces key features of TiDB.\\\\n\\\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\', \\'---\\\\ntitle: TiDB Introduction\\\\nsummary: Learn about the key features and usage scenarios of TiDB.\\\\n---\\\\n\\\\n# TiDB Introduction\\\\n\\\\n<!-- Localization note for TiDB:\\\\n\\\\n- English: use distributed SQL, and start to emphasize HTAP\\\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\\\n- Japanese: use NewSQL because it is well-recognized\\\\n\\\\n-->\\\\n\\\\n[TiDB](https://github.com/pingcap/tidb) (/’taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\\\n\\\\nThe following video introduces key features of TiDB.\\\\n\\\\n<iframe width=\"600\" height=\"450\" src=\"https://www.youtube.com/embed/aWBNNPm21zg?enablejsapi=1\" title=\"Why TiDB?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\', \\'TiDB: A Raft-based HTAP Database\\\\nDongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang∗, Xiaoyu Ma, Fei Xu, Li Shen, Liu Tang,\\\\nYuxing Zhou, Menglong Huang, Wan Wei, Cong Liu, Jian Zhang, Jianjun Li, Xuelian Wu,\\\\nLingyu Song, Ruoxi Sun, Shuaipeng Yu, Lei Zhao, Nicholas Cameron, Liquan Pei, Xin Tang\\\\nPingCAP\\\\n{huang, liuqi, cuiqiu, fangzhuhe, maxiaoyu, xufei, shenli, tl, z, menglong,\\\\nweiwan, liucong, zhangjian, jay, wuxuelian, songlingyu, sunruoxi, yusp,\\\\nzhaolei, nick, liquanpei, tangxin }@pingcap.com\\\\nABSTRACT\\\\nHybrid Transactional and Analytical Processing (HTAP) databases\\\\nrequire processing transactional and analytical queries in isolation\\\\nto remove the interference between them. To achieve this, it is nec-\\\\nessary to maintain different replicas of data speciﬁed for the two\\\\ntypes of queries. However, it is challenging to provide a consistent\\\\nview for distributed replicas within a storage system, where ana-\\\\nlytical requests can efﬁciently read consistent and fresh data from\\\\ntransactional workloads at scale and with high availability.\\\\nTo meet this challenge, we propose extending replicated state\\\\nmachine-based consensus algorithms to provide consistent replicas\\\\nfor HTAP workloads. Based on this novel idea, we present a Raft-\\\\nbased HTAP database: TiDB. In the database, we design a multi-\\\\nRaft storage system which consists of a row store and a column\\\\nstore. The row store is built based on the Raft algorithm. It is scal-\\\\nable to materialize updates from transactional requests with high\\\\navailability. In particular, it asynchronously replicates Raft logs to\\\\nlearners which transform row format to column format for tuples,\\\\nforming a real-time updatable column store. This column store al-\\\\nlows analytical queries to efﬁciently read fresh and consistent data\\\\nwith strong isolation from transactions on the row store. Based on\\\\nthis storage system, we build an SQL engine to process large-scale\\\\ndistributed transactions and expensive analytical queries. The SQL\\\\nengine optimally accesses row-format and column-format replicas\\\\nof data. We also include a powerful analysis engine, TiSpark, to\\\\nhelp TiDB connect to the Hadoop ecosystem. Comprehensive ex-\\\\nperiments show that TiDB achieves isolated high performance un-\\\\nder CH-benCHmark, a benchmark focusing on HTAP workloads.\\\\nPVLDB Reference Format:\\\\nDongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang, Xiaoyu Ma, Fei Xu, Li\\\\nShen, Liu Tang, Yuxing Zhou, Menglong Huang, Wan Wei, Cong Liu, Jian\\\\nZhang, Jianjun Li, Xuelian Wu, Lingyu Song, Ruoxi Sun, Shuaipeng Yu,\\\\nLei Zhao, Nicholas Cameron, Liquan Pei, Xin Tang. TiDB: A Raft-based\\\\nHTAP Database. PVLDB , 13(12): 3072-3084, 2020.\\\\nDOI: https://doi.org/10.14778/3415478.3415535\\\\n1. INTRODUCTION\\\\nRelational database management systems (RDBMS) are popu-\\\\nlar with their relational model, strong transactional guarantees, and\\\\n∗Zhuhe Fang is the corresponding author.\\\\nThis work is licensed under the Creative Commons Attribution-\\\\nNonCommercial-NoDerivatives 4.0 International License. To view a copy\\\\nof this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For\\\\nany use beyond those covered by this license, obtain permission by emailing\\\\ninfo@vldb.org. Copyright is held by the owner/author(s). Publication rights\\\\nlicensed to the VLDB Endowment.\\\\nProceedings of the VLDB Endowment, V ol. 13, No. 12\\\\nISSN 2150-8097.\\\\nDOI: https://doi.org/10.14778/3415478.3415535SQL interface. They are widely adopted in traditional applica-\\\\ntions, like business systems. However, old RDBMSs do not pro-\\\\nvide scalability and high availability. Therefore, at the beginning\\\\nof the 2000s [11], internet applications preferred NoSQL systems\\\\nlike Google Bigtable [12] and DynamoDB [36].\\'].'} output_tags='tidb_summary'\n",
      "MILESTONE: AfterStep3_LLMGeneration, output: Here’s a summary of the key points and definitions related to TiDB, a distributed SQL database system:\n",
      "\n",
      "### Key Points about TiDB:\n",
      "1. **Type**: TiDB is an open-source distributed SQL database that functions as a relational database management system (RDBMS).\n",
      "2. **Designed for**: It is designed for high availability, scalability, and performance, making it suitable for large-scale applications.\n",
      "3. **Compatibility**: TiDB is MySQL-compatible, allowing for easy integration with existing MySQL applications.\n",
      "4. **Workload Support**: It supports Hybrid Transactional and Analytical Processing (HTAP), which enables it to process both transactional (OLTP) and analytical (OLAP) queries effectively.\n",
      "5. **Data Management**: TiDB uses a distributed storage engine (TiKV) and follows the Raft consensus algorithm for consistency and availability.\n",
      "6. **Scalability**: The system is designed to handle high volumes and high concurrency workloads while maintaining strong consistency across distributed nodes.\n",
      "7. **Indexing**: TiDB supports various indexing methods to optimize query performance, enabling efficient data retrieval.\n",
      "8. **Real-Time Data Loading**: It can replicate data between row stores and column stores for real-time analytics, supporting timely and consistent data access.\n",
      "9. **Feature for Streaming Data**: TiCDC allows for streaming data to external systems like Kafka and Hadoop.\n",
      "10. **Vector Search Capabilities**: TiDB has limitations in its vector search functionalities, supporting a maximum of 16,000 dimensions with specific data types and metrics.\n",
      "\n",
      "### Definitions:\n",
      "- **Distributed SQL Database**: A database system that is spread across multiple servers or nodes, allowing for distributed data management and retrieval.\n",
      "- **OLTP (Online Transactional Processing)**: Refers to systems that manage transaction-oriented applications; key for handling day-to-day operations.\n",
      "- **OLAP (Online Analytical Processing)**: Refers to systems designed for analyzing and querying large datasets, typically used in data warehousing and business intelligence.\n",
      "- **HTAP (Hybrid Transactional/Analytical Processing)**: Represents the capability of a system to perform both transactional and analytical processing on the same data, which is essential for real-time analysis and decision making.\n",
      "- **Raft Algorithm**: A consensus algorithm used for distributed systems to ensure consistency and reliability among different nodes in the system.\n",
      "- **TiKV**: The distributed key-value storage engine that serves as the underlying storage layer for TiDB.\n",
      "- **Index**: A data structure that improves the speed of data retrieval operations on a database by allowing faster searches through specific columns.\n",
      "\n",
      "TiDB is increasingly adopted for applications requiring robust, reliable, and scalable database solutions capable of managing diverse workloads efficiently.\n",
      "INFO: Plan executed successfully.\n",
      "\n",
      "Final Summary:\n",
      "Here’s a summary of the key points and definitions related to TiDB, a distributed SQL database system:\n",
      "\n",
      "### Key Points about TiDB:\n",
      "1. **Type**: TiDB is an open-source distributed SQL database that functions as a relational database management system (RDBMS).\n",
      "2. **Designed for**: It is designed for high availability, scalability, and performance, making it suitable for large-scale applications.\n",
      "3. **Compatibility**: TiDB is MySQL-compatible, allowing for easy integration with existing MySQL applications.\n",
      "4. **Workload Support**: It supports Hybrid Transactional and Analytical Processing (HTAP), which enables it to process both transactional (OLTP) and analytical (OLAP) queries effectively.\n",
      "5. **Data Management**: TiDB uses a distributed storage engine (TiKV) and follows the Raft consensus algorithm for consistency and availability.\n",
      "6. **Scalability**: The system is designed to handle high volumes and high concurrency workloads while maintaining strong consistency across distributed nodes.\n",
      "7. **Indexing**: TiDB supports various indexing methods to optimize query performance, enabling efficient data retrieval.\n",
      "8. **Real-Time Data Loading**: It can replicate data between row stores and column stores for real-time analytics, supporting timely and consistent data access.\n",
      "9. **Feature for Streaming Data**: TiCDC allows for streaming data to external systems like Kafka and Hadoop.\n",
      "10. **Vector Search Capabilities**: TiDB has limitations in its vector search functionalities, supporting a maximum of 16,000 dimensions with specific data types and metrics.\n",
      "\n",
      "### Definitions:\n",
      "- **Distributed SQL Database**: A database system that is spread across multiple servers or nodes, allowing for distributed data management and retrieval.\n",
      "- **OLTP (Online Transactional Processing)**: Refers to systems that manage transaction-oriented applications; key for handling day-to-day operations.\n",
      "- **OLAP (Online Analytical Processing)**: Refers to systems designed for analyzing and querying large datasets, typically used in data warehousing and business intelligence.\n",
      "- **HTAP (Hybrid Transactional/Analytical Processing)**: Represents the capability of a system to perform both transactional and analytical processing on the same data, which is essential for real-time analysis and decision making.\n",
      "- **Raft Algorithm**: A consensus algorithm used for distributed systems to ensure consistency and reliability among different nodes in the system.\n",
      "- **TiKV**: The distributed key-value storage engine that serves as the underlying storage layer for TiDB.\n",
      "- **Index**: A data structure that improves the speed of data retrieval operations on a database by allowing faster searches through specific columns.\n",
      "\n",
      "TiDB is increasingly adopted for applications requiring robust, reliable, and scalable database solutions capable of managing diverse workloads efficiently.\n"
     ]
    }
   ],
   "source": [
    "executor = PlanExecutor()\n",
    "success, result = executor.execute_plan(message.parsed)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"\\nPlan execution failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['## Rewrite DDL statements\\n\\nThe following statements are rewritten before being replicated to the downstream.\\n\\n|Original statement|Rewritten statement|\\n|-|-|\\n|`^CREATE DATABASE...`|`^CREATE DATABASE...IF NOT EXISTS`|\\n|`^CREATE TABLE...`|`^CREATE TABLE..IF NOT EXISTS`|\\n|`^DROP DATABASE...`|`^DROP DATABASE...IF EXISTS`|\\n|`^DROP TABLE...`|`^DROP TABLE...IF EXISTS`|\\n|`^DROP INDEX...`|`^DROP INDEX...IF EXISTS`|', '---\\ntitle: Special Handling of DM DDLs\\nsummary: Learn how DM parses and handles DDL statements according to the statement types.\\n---\\n\\n# Special Handling of DM DDLs\\n\\nWhen TiDB Data Migration (DM) migrates data, it parses the DDL statements and handles them according to the statement type and the current migration stage.', '## Rewrite DDL statements\\n\\nThe following statements are rewritten before being replicated to the downstream.\\n\\n|Original statement|Rewritten statement|\\n|-|-|\\n|`^CREATE DATABASE...`|`^CREATE DATABASE...IF NOT EXISTS`|\\n|`^CREATE TABLE...`|`^CREATE TABLE..IF NOT EXISTS`|\\n|`^DROP DATABASE...`|`^DROP DATABASE...IF EXISTS`|\\n|`^DROP TABLE...`|`^DROP TABLE...IF EXISTS`|\\n|`^DROP INDEX...`|`^DROP INDEX...IF EXISTS`|', '## Skip DDL statements\\n\\nThe following statements are not supported by DM, so DM skips them directly after parsing.\\n\\n<table>\\n    <tr>\\n        <th>Description</th>\\n        <th>SQL</th>\\n    </tr>\\n    <tr>\\n        <td>transaction</td>\\n        <td><code>^SAVEPOINT</code></td>\\n    </tr>\\n    <tr>\\n        <td>skip all flush sqls</td>\\n        <td><code>^FLUSH</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">table maintenance</td>\\n        <td><code>^OPTIMIZE\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ANALYZE\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^REPAIR\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td>temporary table</td>\\n        <td><code>^DROP\\\\\\\\s+(\\\\\\\\/\\\\\\\\*\\\\\\\\!40005\\\\\\\\s+)?TEMPORARY\\\\\\\\s+(\\\\\\\\*\\\\\\\\/\\\\\\\\s+)?TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"2\">trigger</td>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?TRIGGER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+TRIGGER</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">procedure</td>\\n        <td><code>^DROP\\\\\\\\s+PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">view</td>\\n        <td><code>^CREATE\\\\\\\\s*(OR REPLACE)?\\\\\\\\s+(ALGORITHM\\\\\\\\s?=.+?)?(DEFINER\\\\\\\\s?=.+?)?\\\\\\\\s+(SQL SECURITY DEFINER)?VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+(ALGORITHM\\\\\\\\s?=.+?)?(DEFINER\\\\\\\\s?=.+?)?(SQL SECURITY DEFINER)?VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"4\">function</td>\\n        <td><code>^CREATE\\\\\\\\s+(AGGREGATE)?\\\\\\\\s*?FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">tableSpace</td>\\n        <td><code>^CREATE\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">event</td>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"7\">account management</td>\\n        <td><code>^GRANT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^REVOKE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^RENAME\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+USER</code></td>\\n    </tr>\\n</table>', '## DDL related statement\\n\\n<CustomContent platform=\"tidb-cloud\">\\n\\n| Statement                                                                                | Description                 |\\n|------------------------------------------------------------------------------------------|-----------------------------|\\n| [`ADMIN CANCEL DDL JOBS`](/sql-statements/sql-statement-admin-cancel-ddl.md)             | Cancels a currently running DDL jobs. |\\n| [`ADMIN CHECKSUM TABLE`](/sql-statements/sql-statement-admin-checksum-table.md)          | Calculates the CRC64 of all rows + indexes of a table. |\\n| [<code>ADMIN CHECK [TABLE\\\\|INDEX]</code>](/sql-statements/sql-statement-admin-check-table-index.md) | Checks for consistency of a table or index. |\\n| [<code>ADMIN SHOW DDL [JOBS\\\\|QUERIES]</code>](/sql-statements/sql-statement-admin-show-ddl.md)      | Shows details about currently running or recently completed DDL jobs. |\\n\\n</CustomContent>\\n\\n<CustomContent platform=\"tidb\">\\n\\n| Statement                                                                                | Description                 |\\n|------------------------------------------------------------------------------------------|-----------------------------|\\n| [`ADMIN CANCEL DDL JOBS`](/sql-statements/sql-statement-admin-cancel-ddl.md)             | Cancels a currently running DDL jobs. |\\n| [`ADMIN CHECKSUM TABLE`](/sql-statements/sql-statement-admin-checksum-table.md)          | Calculates the CRC64 of all rows + indexes of a table. |\\n| [<code>ADMIN CHECK [TABLE\\\\|INDEX]</code>](/sql-statements/sql-statement-admin-check-table-index.md) | Checks for consistency of a table or index. |\\n| [<code>ADMIN SHOW DDL [JOBS\\\\|QUERIES]</code>](/sql-statements/sql-statement-admin-show-ddl.md)      | Shows details about currently running or recently completed DDL jobs. |\\n| [`ADMIN SHOW TELEMETRY`](/sql-statements/sql-statement-admin-show-telemetry.md)      | Shows information that will be reported back to PingCAP as part of the telemetry feature. |\\n\\n</CustomContent>']\n"
     ]
    }
   ],
   "source": [
    "print(['## Rewrite DDL statements\\n\\nThe following statements are rewritten before being replicated to the downstream.\\n\\n|Original statement|Rewritten statement|\\n|-|-|\\n|`^CREATE DATABASE...`|`^CREATE DATABASE...IF NOT EXISTS`|\\n|`^CREATE TABLE...`|`^CREATE TABLE..IF NOT EXISTS`|\\n|`^DROP DATABASE...`|`^DROP DATABASE...IF EXISTS`|\\n|`^DROP TABLE...`|`^DROP TABLE...IF EXISTS`|\\n|`^DROP INDEX...`|`^DROP INDEX...IF EXISTS`|', '---\\ntitle: Special Handling of DM DDLs\\nsummary: Learn how DM parses and handles DDL statements according to the statement types.\\n---\\n\\n# Special Handling of DM DDLs\\n\\nWhen TiDB Data Migration (DM) migrates data, it parses the DDL statements and handles them according to the statement type and the current migration stage.', '## Rewrite DDL statements\\n\\nThe following statements are rewritten before being replicated to the downstream.\\n\\n|Original statement|Rewritten statement|\\n|-|-|\\n|`^CREATE DATABASE...`|`^CREATE DATABASE...IF NOT EXISTS`|\\n|`^CREATE TABLE...`|`^CREATE TABLE..IF NOT EXISTS`|\\n|`^DROP DATABASE...`|`^DROP DATABASE...IF EXISTS`|\\n|`^DROP TABLE...`|`^DROP TABLE...IF EXISTS`|\\n|`^DROP INDEX...`|`^DROP INDEX...IF EXISTS`|', '## Skip DDL statements\\n\\nThe following statements are not supported by DM, so DM skips them directly after parsing.\\n\\n<table>\\n    <tr>\\n        <th>Description</th>\\n        <th>SQL</th>\\n    </tr>\\n    <tr>\\n        <td>transaction</td>\\n        <td><code>^SAVEPOINT</code></td>\\n    </tr>\\n    <tr>\\n        <td>skip all flush sqls</td>\\n        <td><code>^FLUSH</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">table maintenance</td>\\n        <td><code>^OPTIMIZE\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ANALYZE\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^REPAIR\\\\\\\\s+TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td>temporary table</td>\\n        <td><code>^DROP\\\\\\\\s+(\\\\\\\\/\\\\\\\\*\\\\\\\\!40005\\\\\\\\s+)?TEMPORARY\\\\\\\\s+(\\\\\\\\*\\\\\\\\/\\\\\\\\s+)?TABLE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"2\">trigger</td>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?TRIGGER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+TRIGGER</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">procedure</td>\\n        <td><code>^DROP\\\\\\\\s+PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+PROCEDURE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">view</td>\\n        <td><code>^CREATE\\\\\\\\s*(OR REPLACE)?\\\\\\\\s+(ALGORITHM\\\\\\\\s?=.+?)?(DEFINER\\\\\\\\s?=.+?)?\\\\\\\\s+(SQL SECURITY DEFINER)?VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+(ALGORITHM\\\\\\\\s?=.+?)?(DEFINER\\\\\\\\s?=.+?)?(SQL SECURITY DEFINER)?VIEW</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"4\">function</td>\\n        <td><code>^CREATE\\\\\\\\s+(AGGREGATE)?\\\\\\\\s*?FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+FUNCTION</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">tableSpace</td>\\n        <td><code>^CREATE\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+TABLESPACE</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"3\">event</td>\\n        <td><code>^CREATE\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+(DEFINER\\\\\\\\s?=.+?)?EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+EVENT</code></td>\\n    </tr>\\n    <tr>\\n        <td rowspan=\"7\">account management</td>\\n        <td><code>^GRANT</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^REVOKE</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^CREATE\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^ALTER\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^RENAME\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+USER</code></td>\\n    </tr>\\n    <tr>\\n        <td><code>^DROP\\\\\\\\s+USER</code></td>\\n    </tr>\\n</table>', '## DDL related statement\\n\\n<CustomContent platform=\"tidb-cloud\">\\n\\n| Statement                                                                                | Description                 |\\n|------------------------------------------------------------------------------------------|-----------------------------|\\n| [`ADMIN CANCEL DDL JOBS`](/sql-statements/sql-statement-admin-cancel-ddl.md)             | Cancels a currently running DDL jobs. |\\n| [`ADMIN CHECKSUM TABLE`](/sql-statements/sql-statement-admin-checksum-table.md)          | Calculates the CRC64 of all rows + indexes of a table. |\\n| [<code>ADMIN CHECK [TABLE\\\\|INDEX]</code>](/sql-statements/sql-statement-admin-check-table-index.md) | Checks for consistency of a table or index. |\\n| [<code>ADMIN SHOW DDL [JOBS\\\\|QUERIES]</code>](/sql-statements/sql-statement-admin-show-ddl.md)      | Shows details about currently running or recently completed DDL jobs. |\\n\\n</CustomContent>\\n\\n<CustomContent platform=\"tidb\">\\n\\n| Statement                                                                                | Description                 |\\n|------------------------------------------------------------------------------------------|-----------------------------|\\n| [`ADMIN CANCEL DDL JOBS`](/sql-statements/sql-statement-admin-cancel-ddl.md)             | Cancels a currently running DDL jobs. |\\n| [`ADMIN CHECKSUM TABLE`](/sql-statements/sql-statement-admin-checksum-table.md)          | Calculates the CRC64 of all rows + indexes of a table. |\\n| [<code>ADMIN CHECK [TABLE\\\\|INDEX]</code>](/sql-statements/sql-statement-admin-check-table-index.md) | Checks for consistency of a table or index. |\\n| [<code>ADMIN SHOW DDL [JOBS\\\\|QUERIES]</code>](/sql-statements/sql-statement-admin-show-ddl.md)      | Shows details about currently running or recently completed DDL jobs. |\\n| [`ADMIN SHOW TELEMETRY`](/sql-statements/sql-statement-admin-show-telemetry.md)      | Shows information that will be reported back to PingCAP as part of the telemetry feature. |\\n\\n</CustomContent>'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tidb.ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
